{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-04T07:20:31.705925Z",
     "iopub.status.busy": "2025-01-04T07:20:31.705632Z",
     "iopub.status.idle": "2025-01-04T07:20:31.732801Z",
     "shell.execute_reply": "2025-01-04T07:20:31.731899Z",
     "shell.execute_reply.started": "2025-01-04T07:20:31.705895Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/model-dataset-new-1/2015.csv\n",
      "/kaggle/input/model-dataset-new-1/2017.csv\n",
      "/kaggle/input/model-dataset-new-1/2019.csv\n",
      "/kaggle/input/model-dataset-new-1/main_data.csv\n",
      "/kaggle/input/model-dataset-new-1/2018.csv\n",
      "/kaggle/input/model-dataset-new-1/2016.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:42:39.520825Z",
     "iopub.status.busy": "2025-01-04T07:42:39.520485Z",
     "iopub.status.idle": "2025-01-04T07:42:44.487535Z",
     "shell.execute_reply": "2025-01-04T07:42:44.486505Z",
     "shell.execute_reply.started": "2025-01-04T07:42:39.520801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:45:07.245050Z",
     "iopub.status.busy": "2025-01-04T07:45:07.244729Z",
     "iopub.status.idle": "2025-01-04T07:45:07.251833Z",
     "shell.execute_reply": "2025-01-04T07:45:07.250993Z",
     "shell.execute_reply.started": "2025-01-04T07:45:07.245025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import logging\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from gtts import gTTS\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import spacy\n",
    "import os\n",
    "import logging\n",
    "import warnings \n",
    "import os\n",
    "import joblib\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import spacy\n",
    "import logging\n",
    "\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# # Load spaCy model for NER\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:45:12.170349Z",
     "iopub.status.busy": "2025-01-04T07:45:12.170026Z",
     "iopub.status.idle": "2025-01-04T07:45:12.174102Z",
     "shell.execute_reply": "2025-01-04T07:45:12.172981Z",
     "shell.execute_reply.started": "2025-01-04T07:45:12.170323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load and Preprocess the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:45:12.251052Z",
     "iopub.status.busy": "2025-01-04T07:45:12.250736Z",
     "iopub.status.idle": "2025-01-04T07:45:12.257660Z",
     "shell.execute_reply": "2025-01-04T07:45:12.256655Z",
     "shell.execute_reply.started": "2025-01-04T07:45:12.251028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    try:\n",
    "        logging.info(f\"Loading data from {file_path}\")\n",
    "        # Load data\n",
    "        if file_path.endswith('.csv'):\n",
    "            data = pd.read_csv(file_path)\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            data = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.txt'):\n",
    "            data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format.\")\n",
    "        \n",
    "        logging.info(\"Data loaded successfully\")\n",
    "        \n",
    "        # Detect and convert data types\n",
    "        for col in data.columns:\n",
    "            try:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Handle missing values\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "        \n",
    "        # Handle categorical data\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "        \n",
    "        # Normalize numeric data\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        scaler = StandardScaler()\n",
    "        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "        \n",
    "        logging.info(\"Data preprocessing completed\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading and preprocessing data: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:45:12.940579Z",
     "iopub.status.busy": "2025-01-04T07:45:12.940230Z",
     "iopub.status.idle": "2025-01-04T07:45:12.945118Z",
     "shell.execute_reply": "2025-01-04T07:45:12.944316Z",
     "shell.execute_reply.started": "2025-01-04T07:45:12.940553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "def perform_eda(data):\n",
    "    try:\n",
    "        logging.info(\"Performing EDA...\")\n",
    "        \n",
    "        # Basic EDA summary\n",
    "        eda_summary = {\n",
    "            \"shape\": data.shape,\n",
    "            \"columns\": data.columns.tolist(),\n",
    "            \"dtypes\": data.dtypes.apply(lambda x: x.name).to_dict(),\n",
    "            \"null_counts\": data.isnull().sum().to_dict(),\n",
    "            \"describe\": data.describe(include='all').to_dict()\n",
    "        }\n",
    "        \n",
    "        # Correlation analysis\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            eda_summary[\"correlation\"] = data[numeric_cols].corr().to_dict()\n",
    "        \n",
    "        # Unique value counts\n",
    "        eda_summary[\"unique_counts\"] = {col: data[col].nunique() for col in data.columns}\n",
    "        \n",
    "        # Missing value analysis\n",
    "        eda_summary[\"missing_value_analysis\"] = {\n",
    "            \"total_missing\": data.isnull().sum().sum(),\n",
    "            \"missing_per_column\": data.isnull().sum().to_dict(),\n",
    "            \"missing_percentage_per_column\": (data.isnull().sum() / len(data) * 100).to_dict()\n",
    "        }\n",
    "        \n",
    "        # Categorical data analysis\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        eda_summary[\"categorical_summary\"] = {\n",
    "            col: data[col].value_counts().to_dict() for col in categorical_cols\n",
    "        }\n",
    "        \n",
    "        # Outlier detection\n",
    "        eda_summary[\"outliers\"] = {\n",
    "            col: data[col][((data[col] - data[col].mean()) / data[col].std()).abs() > 3].tolist() for col in numeric_cols\n",
    "        }\n",
    "        \n",
    "        # Distribution analysis\n",
    "        eda_summary[\"distribution\"] = {\n",
    "            col: data[col].describe().to_dict() for col in numeric_cols\n",
    "        }\n",
    "        \n",
    "        # Time series analysis\n",
    "        date_cols = [col for col in data.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "        if date_cols:\n",
    "            eda_summary[\"time_series_analysis\"] = {\n",
    "                col: data.set_index(col).resample('M').mean().to_dict() for col in date_cols if pd.api.types.is_datetime64_any_dtype(data[col])\n",
    "            }\n",
    "        \n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        return eda_summary\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing EDA: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:45:15.030947Z",
     "iopub.status.busy": "2025-01-04T07:45:15.030627Z",
     "iopub.status.idle": "2025-01-04T07:45:21.023544Z",
     "shell.execute_reply": "2025-01-04T07:45:21.022800Z",
     "shell.execute_reply.started": "2025-01-04T07:45:15.030921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b509eb89258e4949a6253369306b7e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c855bb416385492fa2c9da9dc413d042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0bfa33d1604d098a6f9484de75ce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6578a8e82145f1bbc374b886174635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286b3ef142c14371a3d8c46b3a3432f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026a580ac4144f92823b3a614418dd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_models(model_name=\"facebook/bart-large-cnn\", save_directory=\"models\"):\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "    # Save the tokenizer and model as .pkl files\n",
    "    with open(os.path.join(save_directory, \"facebook_tokenizer.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    with open(os.path.join(save_directory, \"facebook_model.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # Load and save the spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    with open(os.path.join(save_directory, \"spacy_model.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(nlp, f)\n",
    "    \n",
    "    logging.info(f\"Models saved to {save_directory}\")\n",
    "\n",
    "# Call this function once to save the models\n",
    "save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:45:23.786142Z",
     "iopub.status.busy": "2025-01-04T07:45:23.785678Z",
     "iopub.status.idle": "2025-01-04T07:45:25.107997Z",
     "shell.execute_reply": "2025-01-04T07:45:25.107054Z",
     "shell.execute_reply.started": "2025-01-04T07:45:23.786105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_models(model_directory=\"models\"):\n",
    "    # Load the tokenizer and model from the saved .pkl files\n",
    "    with open(os.path.join(model_directory, \"facebook_tokenizer.pkl\"), \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    with open(os.path.join(model_directory, \"facebook_model.pkl\"), \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Load the spaCy model from the saved .pkl file\n",
    "    with open(os.path.join(model_directory, \"spacy_model.pkl\"), \"rb\") as f:\n",
    "        nlp = pickle.load(f)\n",
    "    \n",
    "    return tokenizer, model, nlp\n",
    "\n",
    "# Load the models\n",
    "tokenizer, model, nlp = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:48:47.526319Z",
     "iopub.status.busy": "2025-01-04T07:48:47.526029Z",
     "iopub.status.idle": "2025-01-04T07:48:47.533502Z",
     "shell.execute_reply": "2025-01-04T07:48:47.532584Z",
     "shell.execute_reply.started": "2025-01-04T07:48:47.526299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "def analyze_prompt_for_insights(prompt, eda_summary):\n",
    "    try:\n",
    "        logging.info(\"Analyzing prompt for insights\")\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        input_ids = inputs.input_ids\n",
    "        attention_mask = inputs.attention_mask\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=200,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            no_repeat_ngram_size=2,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        logging.debug(f\"Generated text from model: {generated_text}\")\n",
    "        \n",
    "        insights, columns = extract_insights_and_columns_from_text(generated_text, eda_summary)\n",
    "        \n",
    "        if not insights:\n",
    "            logging.warning(\"No insights could be extracted from the provided prompt. Using fallback insights.\")\n",
    "            insights = fallback_insights(eda_summary)\n",
    "        \n",
    "        if not columns:\n",
    "            logging.warning(\"No columns could be extracted from the provided prompt. Using fallback columns.\")\n",
    "            columns = fallback_columns(eda_summary)\n",
    "        \n",
    "        logging.info(f\"Insights extracted: {insights}\")\n",
    "        logging.info(f\"Columns extracted: {columns}\")\n",
    "        return insights, columns\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def extract_insights_and_columns_from_text(text, eda_summary):\n",
    "    possible_insights = [\"trend\", \"comparison\", \"distribution\", \"correlation\", \"pattern\", \"anomaly\", \"outlier\", \"relationship\", \"performance\", \"growth\"]\n",
    "    insights = []\n",
    "    columns = []\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    for insight in possible_insights:\n",
    "        if re.search(r'\\b' + re.escape(insight) + r'\\b', text):\n",
    "            insights.append(insight)\n",
    "    \n",
    "    # Extract column names from the text\n",
    "    # Assuming column names are mentioned in the text and are separated by commas\n",
    "    column_pattern = re.compile(r'\\b(?:columns|fields|attributes|features)\\b\\s*:\\s*([\\w\\s,]+)')\n",
    "    match = column_pattern.search(text)\n",
    "    if match:\n",
    "        columns = [col.strip() for col in match.group(1).split(',')]\n",
    "    \n",
    "    # Validate columns against EDA summary\n",
    "    valid_columns = [col for col in columns if col in eda_summary['columns']]\n",
    "    \n",
    "    return insights, valid_columns\n",
    "\n",
    "def fallback_insights(eda_summary):\n",
    "    # Fallback logic to generate default insights based on EDA summary\n",
    "    insights = []\n",
    "    if len(eda_summary['columns']) > 1:\n",
    "        insights.append(\"correlation\")\n",
    "    if any('date' in col.lower() or 'time' in col.lower() for col in eda_summary['columns']):\n",
    "        insights.append(\"trend\")\n",
    "    if any(eda_summary['dtypes'][col] == 'object' for col in eda_summary['columns']):\n",
    "        insights.append(\"distribution\")\n",
    "    return insights\n",
    "\n",
    "def fallback_columns(eda_summary):\n",
    "    # Fallback logic to generate default columns based on EDA summary\n",
    "    numeric_columns = [col for col in eda_summary['columns'] if eda_summary['dtypes'][col] in ['float64', 'int64']]\n",
    "    if len(numeric_columns) >= 2:\n",
    "        return numeric_columns[:2]\n",
    "    return numeric_columns\n",
    "# def generate_frames(data, insights, columns):\n",
    "#     if not data.empty and columns:\n",
    "#         # Generate frames based on insights and columns\n",
    "#         frames = []  # Placeholder for actual frame generation logic\n",
    "#         logging.info(f\"Generated {len(frames)} frames based on insights and columns.\")\n",
    "#         return frames\n",
    "#     else:\n",
    "#         logging.error(\"Value error: No frames generated from data.\")\n",
    "#         return []\n",
    "\n",
    "# # Call the function\n",
    "# insights, columns = analyze_prompt_for_insights(prompt, eda_summary)\n",
    "\n",
    "# # Generate frames\n",
    "# frames = generate_frames(data, insights, columns)\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"Insights: {insights}\")\n",
    "# print(f\"Columns: {columns}\")\n",
    "# print(f\"Frames: {frames}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:48:48.997762Z",
     "iopub.status.busy": "2025-01-04T07:48:48.997442Z",
     "iopub.status.idle": "2025-01-04T07:48:49.012660Z",
     "shell.execute_reply": "2025-01-04T07:48:49.011672Z",
     "shell.execute_reply.started": "2025-01-04T07:48:48.997737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import imageio\n",
    "\n",
    "def generate_animated_frames(data, insights, columns, output_dir=\"frames\"):\n",
    "    logging.info(\"Generating animated frames from data\")\n",
    "    frames = []\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Log the data columns and types\n",
    "    logging.debug(f\"Data columns: {data.columns}\")\n",
    "    logging.debug(f\"Data types: {data.dtypes}\")\n",
    "    \n",
    "    # Generate frames based on insights\n",
    "    for insight in insights:\n",
    "        logging.debug(f\"Processing insight: {insight}\")\n",
    "        if insight == \"trend\":\n",
    "            logging.info(\"Generating trend frames\")\n",
    "            date_column = None\n",
    "            for col in data.columns:\n",
    "                if 'date' in col.lower() or 'time' in col.lower():\n",
    "                    date_column = col\n",
    "                    break\n",
    "            \n",
    "            if date_column and columns:\n",
    "                numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "                if len(numeric_columns) > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "                    ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "                    ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "                    ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "                    ax.set_xlabel('Time')\n",
    "                    ax.set_ylabel('Values')\n",
    "                    ax.legend()\n",
    "\n",
    "                    def update(frame):\n",
    "                        for line, col in zip(lines, numeric_columns):\n",
    "                            line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "                        return lines\n",
    "\n",
    "                    ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                    for i in range(len(data)):\n",
    "                        update(i)\n",
    "                        buf = io.BytesIO()\n",
    "                        fig.savefig(buf, format='png')\n",
    "                        buf.seek(0)\n",
    "                        img = Image.open(buf)\n",
    "                        frames.append(np.array(img))\n",
    "                    plt.close(fig)\n",
    "                else:\n",
    "                    logging.warning(\"No numeric columns found for trend insight\")\n",
    "            else:\n",
    "                logging.warning(\"No date column or relevant columns found for trend insight\")\n",
    "        \n",
    "        elif insight == \"comparison\":\n",
    "            logging.info(\"Generating comparison frames\")\n",
    "            if len(columns) == 2 and all(col in data.columns for col in columns):\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                categories = data[columns[0]].unique()\n",
    "                bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "                ax.set_ylim(0, data[columns[1]].max())\n",
    "                ax.set_title('Animated Bar Chart')\n",
    "                ax.set_xlabel(columns[0])\n",
    "                ax.set_ylabel(columns[1])\n",
    "\n",
    "                def update_bar(frame):\n",
    "                    for bar, category in zip(bars, categories):\n",
    "                        bar.set_height(data[data[columns[0]] == category][columns[1]].iloc[frame])\n",
    "                    return bars\n",
    "\n",
    "                ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n",
    "                for i in range(len(data)):\n",
    "                    update_bar(i)\n",
    "                    buf = io.BytesIO()\n",
    "                    fig.savefig(buf, format='png')\n",
    "                    buf.seek(0)\n",
    "                    img = Image.open(buf)\n",
    "                    frames.append(np.array(img))\n",
    "                plt.close(fig)\n",
    "            else:\n",
    "                logging.warning(\"Required columns for comparison insight not found or incorrect\")\n",
    "        \n",
    "        elif insight == \"distribution\":\n",
    "            logging.info(\"Generating distribution frames\")\n",
    "            numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "            if len(numeric_columns) > 0:\n",
    "                for col in numeric_columns:\n",
    "                    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "                    sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "                    ax.set_title(f\"Distribution of {col}\")\n",
    "                    buf = io.BytesIO()\n",
    "                    fig.savefig(buf, format='png')\n",
    "                    buf.seek(0)\n",
    "                    img = Image.open(buf)\n",
    "                    frames.append(np.array(img))\n",
    "                    plt.close(fig)\n",
    "            else:\n",
    "                logging.warning(\"No numeric columns found for distribution insight\")\n",
    "        \n",
    "        elif insight == \"correlation\":\n",
    "            logging.info(\"Generating correlation frames\")\n",
    "            numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "            if len(numeric_columns) > 1:\n",
    "                corr_matrix = data[numeric_columns].corr()\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "                ax.set_title('Correlation Matrix')\n",
    "                buf = io.BytesIO()\n",
    "                fig.savefig(buf, format='png')\n",
    "                buf.seek(0)\n",
    "                img = Image.open(buf)\n",
    "                frames.append(np.array(img))\n",
    "                plt.close(fig)\n",
    "            else:\n",
    "                logging.warning(\"Not enough numeric columns for correlation insight\")\n",
    "        \n",
    "        elif insight == \"pie\":\n",
    "            logging.info(\"Generating pie chart frames\")\n",
    "            if len(columns) == 2 and all(col in data.columns for col in columns):\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                def update_pie(frame):\n",
    "                    ax.clear()\n",
    "                    ax.pie(data[columns[1]][:frame], labels=data[columns[0]][:frame], autopct='%1.1f%%')\n",
    "                    ax.set_title('Animated Pie Chart')\n",
    "\n",
    "                ani = FuncAnimation(fig, update_pie, frames=len(data), blit=True)\n",
    "                for i in range(len(data)):\n",
    "                    update_pie(i)\n",
    "                    buf = io.BytesIO()\n",
    "                    fig.savefig(buf, format='png')\n",
    "                    buf.seek(0)\n",
    "                    img = Image.open(buf)\n",
    "                    frames.append(np.array(img))\n",
    "                plt.close(fig)\n",
    "            else:\n",
    "                logging.warning(\"Required columns for pie chart insight not found or incorrect\")\n",
    "        \n",
    "        elif insight == \"pattern\":\n",
    "            logging.info(\"Generating pattern frames\")\n",
    "            # Example: Detecting and animating a repeating pattern in a time series\n",
    "            date_column = None\n",
    "            for col in data.columns:\n",
    "                if 'date' in col.lower() or 'time' in col.lower():\n",
    "                    date_column = col\n",
    "                    break\n",
    "            \n",
    "            if date_column and columns:\n",
    "                numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "                if len(numeric_columns) > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "                    ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "                    ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "                    ax.set_title(f\"Pattern Detection for {', '.join(numeric_columns)}\")\n",
    "                    ax.set_xlabel('Time')\n",
    "                    ax.set_ylabel('Values')\n",
    "                    ax.legend()\n",
    "\n",
    "                    def update(frame):\n",
    "                        for line, col in zip(lines, numeric_columns):\n",
    "                            line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "                        return lines\n",
    "\n",
    "                    ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                    for i in range(len(data)):\n",
    "                        update(i)\n",
    "                        buf = io.BytesIO()\n",
    "                        fig.savefig(buf, format='png')\n",
    "                        buf.seek(0)\n",
    "                        img = Image.open(buf)\n",
    "                        frames.append(np.array(img))\n",
    "                    plt.close(fig)\n",
    "                else:\n",
    "                    logging.warning(\"No numeric columns found for pattern insight\")\n",
    "            else:\n",
    "                logging.warning(\"No date column or relevant columns found for pattern insight\")\n",
    "\n",
    "        elif insight == \"anomaly\":\n",
    "            logging.info(\"Generating anomaly frames\")\n",
    "            # Example: Highlighting anomalies in a time series\n",
    "            date_column = None\n",
    "            for col in data.columns:\n",
    "                if 'date' in col.lower() or 'time' in col.lower():\n",
    "                    date_column = col\n",
    "                    break\n",
    "            \n",
    "            if date_column and columns:\n",
    "                numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "                if len(numeric_columns) > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "                    ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "                    ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "                    ax.set_title(f\"Anomaly Detection for {', '.join(numeric_columns)}\")\n",
    "                    ax.set_xlabel('Time')\n",
    "                    ax.set_ylabel('Values')\n",
    "                    ax.legend()\n",
    "\n",
    "                    def update(frame):\n",
    "                        for line, col in zip(lines, numeric_columns):\n",
    "                            line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "                            if data[col][frame] > data[col].mean() + 3 * data[col].std() or data[col][frame] < data[col].mean() - 3 * data[col].std():\n",
    "                                line.set_color('red')\n",
    "                            else:\n",
    "                                line.set_color('blue')\n",
    "                        return lines\n",
    "\n",
    "                    ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                    for i in range(len(data)):\n",
    "                        update(i)\n",
    "                        buf = io.BytesIO()\n",
    "                        fig.savefig(buf, format='png')\n",
    "                        buf.seek(0)\n",
    "                        img = Image.open(buf)\n",
    "                        frames.append(np.array(img))\n",
    "                    plt.close(fig)\n",
    "                else:\n",
    "                    logging.warning(\"No numeric columns found for anomaly insight\")\n",
    "            else:\n",
    "                logging.warning(\"No date column or relevant columns found for anomaly insight\")\n",
    "\n",
    "        elif insight == \"outlier\":\n",
    "            logging.info(\"Generating outlier frames\")\n",
    "            # Example: Highlighting outliers in a scatter plot\n",
    "            if len(columns) == 2 and all(col in data.columns for col in columns):\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                scatter = ax.scatter(data[columns[0]], data[columns[1]], c='blue')\n",
    "                ax.set_title('Outlier Detection')\n",
    "                ax.set_xlabel(columns[0])\n",
    "                ax.set_ylabel(columns[1])\n",
    "\n",
    "                def update(frame):\n",
    "                    ax.clear()\n",
    "                    ax.scatter(data[columns[0]], data[columns[1]], c='blue')\n",
    "                    outliers = data[(data[columns[1]] > data[columns[1]].mean() + 3 * data[columns[1]].std()) | (data[columns[1]] < data[columns[1]].mean() - 3 * data[columns[1]].std())]\n",
    "                    ax.scatter(outliers[columns[0]], outliers[columns[1]], c='red')\n",
    "                    ax.set_title('Outlier Detection')\n",
    "                    ax.set_xlabel(columns[0])\n",
    "                    ax.set_ylabel(columns[1])\n",
    "                    return scatter,\n",
    "\n",
    "                ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                for i in range(len(data)):\n",
    "                    update(i)\n",
    "                    buf = io.BytesIO()\n",
    "                    fig.savefig(buf, format='png')\n",
    "                    buf.seek(0)\n",
    "                    img = Image.open(buf)\n",
    "                    frames.append(np.array(img))\n",
    "                plt.close(fig)\n",
    "            else:\n",
    "                logging.warning(\"Required columns for outlier insight not found or incorrect\")\n",
    "\n",
    "        elif insight == \"relationship\":\n",
    "            logging.info(\"Generating relationship frames\")\n",
    "            # Example: Showing relationship between two variables over time\n",
    "            if len(columns) == 2 and all(col in data.columns for col in columns):\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                scatter = ax.scatter(data[columns[0]], data[columns[1]], c='blue')\n",
    "                ax.set_title('Relationship Over Time')\n",
    "                ax.set_xlabel(columns[0])\n",
    "                ax.set_ylabel(columns[1])\n",
    "\n",
    "                def update(frame):\n",
    "                    ax.clear()\n",
    "                    ax.scatter(data[columns[0]][:frame], data[columns[1]][:frame], c='blue')\n",
    "                    ax.set_title('Relationship Over Time')\n",
    "                    ax.set_xlabel(columns[0])\n",
    "                    ax.set_ylabel(columns[1])\n",
    "                    return scatter,\n",
    "\n",
    "                ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                for i in range(len(data)):\n",
    "                    update(i)\n",
    "                    buf = io.BytesIO()\n",
    "                    fig.savefig(buf, format='png')\n",
    "                    buf.seek(0)\n",
    "                    img = Image.open(buf)\n",
    "                    frames.append(np.array(img))\n",
    "                plt.close(fig)\n",
    "            else:\n",
    "                logging.warning(\"Required columns for relationship insight not found or incorrect\")\n",
    "\n",
    "        elif insight == \"performance\":\n",
    "            logging.info(\"Generating performance frames\")\n",
    "            # Example: Showing performance metrics over time\n",
    "            date_column = None\n",
    "            for col in data.columns:\n",
    "                if 'date' in col.lower() or 'time' in col.lower():\n",
    "                    date_column = col\n",
    "                    break\n",
    "            \n",
    "            if date_column and columns:\n",
    "                numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "                if len(numeric_columns) > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "                    ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "                    ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "                    ax.set_title(f\"Performance Metrics for {', '.join(numeric_columns)}\")\n",
    "                    ax.set_xlabel('Time')\n",
    "                    ax.set_ylabel('Values')\n",
    "                    ax.legend()\n",
    "\n",
    "                    def update(frame):\n",
    "                        for line, col in zip(lines, numeric_columns):\n",
    "                            line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "                        return lines\n",
    "\n",
    "                    ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                    for i in range(len(data)):\n",
    "                        update(i)\n",
    "                        buf = io.BytesIO()\n",
    "                        fig.savefig(buf, format='png')\n",
    "                        buf.seek(0)\n",
    "                        img = Image.open(buf)\n",
    "                        frames.append(np.array(img))\n",
    "                    plt.close(fig)\n",
    "                else:\n",
    "                    logging.warning(\"No numeric columns found for performance insight\")\n",
    "            else:\n",
    "                logging.warning(\"No date column or relevant columns found for performance insight\")\n",
    "\n",
    "        elif insight == \"growth\":\n",
    "            logging.info(\"Generating growth frames\")\n",
    "            # Example: Showing growth over time\n",
    "            date_column = None\n",
    "            for col in data.columns:\n",
    "                if 'date' in col.lower() or 'time' in col.lower():\n",
    "                    date_column = col\n",
    "                    break\n",
    "            \n",
    "            if date_column and columns:\n",
    "                numeric_columns = [col for col in columns if col in data.columns and data[col].dtype in ['float64', 'int64']]\n",
    "                if len(numeric_columns) > 0:\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "                    ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "                    ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "                    ax.set_title(f\"Growth Over Time for {', '.join(numeric_columns)}\")\n",
    "                    ax.set_xlabel('Time')\n",
    "                    ax.set_ylabel('Values')\n",
    "                    ax.legend()\n",
    "\n",
    "                    def update(frame):\n",
    "                        for line, col in zip(lines, numeric_columns):\n",
    "                            line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "                        return lines\n",
    "\n",
    "                    ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "                    for i in range(len(data)):\n",
    "                        update(i)\n",
    "                        buf = io.BytesIO()\n",
    "                        fig.savefig(buf, format='png')\n",
    "                        buf.seek(0)\n",
    "                        img = Image.open(buf)\n",
    "                        frames.append(np.array(img))\n",
    "                    plt.close(fig)\n",
    "                else:\n",
    "                    logging.warning(\"No numeric columns found for growth insight\")\n",
    "            else:\n",
    "                logging.warning(\"No date column or relevant columns found for growth insight\")\n",
    "        \n",
    "        else:\n",
    "            logging.warning(f\"Unhandled insight type: {insight}\")\n",
    "    \n",
    "    logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "    \n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:48:50.942059Z",
     "iopub.status.busy": "2025-01-04T07:48:50.941646Z",
     "iopub.status.idle": "2025-01-04T07:48:50.950834Z",
     "shell.execute_reply": "2025-01-04T07:48:50.949891Z",
     "shell.execute_reply.started": "2025-01-04T07:48:50.942028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_video_from_frames(frames, audio_file=None, video_file=\"final_production_model.mp4\"):\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "    logging.info(\"Creating video from frames\")\n",
    "    video_clips = []\n",
    "    for frame in frames:\n",
    "        img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n",
    "        img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n",
    "        video_clips.append(img_clip)\n",
    "    \n",
    "    video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        video = video.set_audio(audio)\n",
    "    \n",
    "    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "    logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "def generate_infographic_video(data, insights, columns,audio_file=None, title_image=\"title_screen.png\"):\n",
    "    frames = generate_animated_frames(data, insights, columns)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_image_clip = Image.open(title_image)\n",
    "        title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "        title_image_clip = np.array(title_image_clip)\n",
    "        frames.insert(0, title_image_clip)\n",
    "    \n",
    "    create_video_from_frames(frames, audio_file)\n",
    "    print(\"Video successfully generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:48:53.140315Z",
     "iopub.status.busy": "2025-01-04T07:48:53.140031Z",
     "iopub.status.idle": "2025-01-04T07:48:53.144027Z",
     "shell.execute_reply": "2025-01-04T07:48:53.143289Z",
     "shell.execute_reply.started": "2025-01-04T07:48:53.140293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_narration(text, output_file=\"narration.mp3\", lang='en', slow=False, tld='com'):\n",
    "    \"\"\"\n",
    "    Generate narration audio from text using gTTS (Google Text-to-Speech).\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to be converted to speech.\n",
    "    output_file (str): The file path where the audio file will be saved.\n",
    "    lang (str): The language in which the text will be spoken. Default is 'en' (English).\n",
    "    slow (bool): Whether to speak slowly. Default is False.\n",
    "    tld (str): Top-level domain for the Google Translate host. Default is 'com'.\n",
    "\n",
    "    Returns:\n",
    "    str: The file path of the saved audio file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Generating narration for text: {text}\")\n",
    "        tts = gTTS(text=text, lang=lang, slow=slow, tld=tld)\n",
    "        tts.save(output_file)\n",
    "        logging.info(f\"Narration saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating narration: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "# narration_text = \"This is a detailed narration of the data analysis results.\"\n",
    "# narration_file = generate_narration(narration_text)\n",
    "# print(f\"Narration file saved at: {narration_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:48:55.191094Z",
     "iopub.status.busy": "2025-01-04T07:48:55.190782Z",
     "iopub.status.idle": "2025-01-04T07:48:55.197334Z",
     "shell.execute_reply": "2025-01-04T07:48:55.196331Z",
     "shell.execute_reply.started": "2025-01-04T07:48:55.191070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def data_storytelling_pipeline(file_path, prompt):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights, columns = analyze_prompt_for_insights(prompt, eda_summary)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        logging.debug(f\"Extracted columns: {columns}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. Insights: {', '.join(insights)}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        video_file = generate_infographic_video(data, insights, columns, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        \n",
    "        return video_file\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:48:56.581161Z",
     "iopub.status.busy": "2025-01-04T07:48:56.580874Z",
     "iopub.status.idle": "2025-01-04T07:49:18.809164Z",
     "shell.execute_reply": "2025-01-04T07:49:18.808330Z",
     "shell.execute_reply.started": "2025-01-04T07:48:56.581139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading and preprocessing data...\n",
      "INFO:root:Loading data from D:\\1OOx-enginners-hackathon-submission-2\\data\\2015.csv\n",
      "INFO:root:Data loaded successfully\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1051: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1056: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1076: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "\n",
      "INFO:root:Data preprocessing completed\n",
      "INFO:root:Performing EDA...\n",
      "INFO:root:Performing EDA...\n",
      "INFO:root:Analyzing the user's prompt...\n",
      "INFO:root:Analyzing prompt for insights\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING:root:No insights could be extracted from the provided prompt. Using fallback insights.\n",
      "WARNING:root:No columns could be extracted from the provided prompt. Using fallback columns.\n",
      "INFO:root:Insights extracted: ['correlation']\n",
      "INFO:root:Columns extracted: ['Country', 'Region']\n",
      "INFO:root:Generating narration...\n",
      "INFO:root:Generating narration for text: Here is the analysis based on the prompt: analyse the region columns.. Insights: correlation\n",
      "INFO:root:Narration saved to narration.mp3\n",
      "INFO:root:Creating the infographic video...\n",
      "INFO:root:Generating animated frames from data\n",
      "INFO:root:Generating correlation frames\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\matrix.py:202: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = np.nanmin(calc_data)\n",
      "\n",
      "WARNING:py.warnings:c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\matrix.py:207: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = np.nanmax(calc_data)\n",
      "\n",
      "INFO:root:Generated 1 animated frames\n",
      "INFO:root:Creating video from frames\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video final_production_model.mp4.\n",
      "MoviePy - Writing audio in final_production_modelTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_production_model.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Video saved as final_production_model.mp4         \n",
      "INFO:root:Pipeline completed successfully in 29.08 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_production_model.mp4\n",
      "Video successfully generated!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "prompt = \"analyse the region columns.\"\n",
    "# audio_file = \"D:\\\\1OOx-enginners-hackathon-submission-2\\\\uploads\\\\audio_files\"\n",
    "# title_image = \"D:\\\\1OOx-enginners-hackathon-submission-2\\\\outputs\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "video_file = data_storytelling_pipeline(file_path, prompt)\n",
    "print(video_file)\n",
    "# return video_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DONE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD MODEL CODE IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:42:00.637118Z",
     "iopub.status.busy": "2025-01-04T07:42:00.636783Z",
     "iopub.status.idle": "2025-01-04T07:42:00.641168Z",
     "shell.execute_reply": "2025-01-04T07:42:00.640237Z",
     "shell.execute_reply.started": "2025-01-04T07:42:00.637092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "\n",
    "# def generate_visualizations(data, insights):\n",
    "#     try:\n",
    "#         logging.info(\"Generating visualizations\")\n",
    "#         if data.empty:\n",
    "#             raise ValueError(\"Data is empty.\")\n",
    "#         if not insights:\n",
    "#             raise ValueError(\"No insights available to generate visualizations.\")\n",
    "        \n",
    "#         visuals = []\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "        \n",
    "#         if 'Date' in data.columns or 'Datetime' in data.columns:\n",
    "#             time_column = 'Date' if 'Date' in data.columns else 'Datetime'\n",
    "#             if numeric_columns.any():\n",
    "#                 fig = px.line(data, x=time_column, y=numeric_columns, title=f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#                 visuals.append(fig)\n",
    "        \n",
    "#         if len(numeric_columns) > 1:\n",
    "#             corr_matrix = data[numeric_columns].corr()\n",
    "#             fig = px.imshow(corr_matrix, text_auto=True, title='Correlation Matrix')\n",
    "#             visuals.append(fig)\n",
    "        \n",
    "#         for col in categorical_columns:\n",
    "#             fig = px.histogram(data, x=col, title=f\"Distribution of {col}\")\n",
    "#             visuals.append(fig)\n",
    "        \n",
    "#         if len(numeric_columns) > 1:\n",
    "#             fig = px.scatter_matrix(data, dimensions=numeric_columns, title='Pairwise Relationships')\n",
    "#             visuals.append(fig)\n",
    "        \n",
    "#         if not visuals:\n",
    "#             return None\n",
    "        \n",
    "#         logging.info(f\"Generated {len(visuals)} visualizations\")\n",
    "#         return visuals\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error generating visualizations: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # # Example usage:\n",
    "# # file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# # data = pd.read_csv(file_path)\n",
    "# # insights = \"Sample insights based on the data\"\n",
    "# # visuals = generate_visualizations(data, insights)\n",
    "\n",
    "# # # To display the visualizations in a Jupyter notebook\n",
    "# # for fig in visuals:\n",
    "# #     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:42:07.251969Z",
     "iopub.status.busy": "2025-01-04T07:42:07.251664Z",
     "iopub.status.idle": "2025-01-04T07:42:07.255920Z",
     "shell.execute_reply": "2025-01-04T07:42:07.254919Z",
     "shell.execute_reply.started": "2025-01-04T07:42:07.251947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import logging\n",
    "\n",
    "# def generate_default_frames(data):\n",
    "#     logging.info(\"Generating default frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             plt.figure(figsize=(10, 6))\n",
    "#             for col in numeric_columns:\n",
    "#                 plt.plot(data[date_column], data[col], label=col)\n",
    "#             plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             plt.xlabel('Time')\n",
    "#             plt.ylabel('Values')\n",
    "#             plt.xticks(rotation=45)\n",
    "#             plt.legend()\n",
    "#             frames.append(plt)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "#         plt.title('Correlation Matrix')\n",
    "#         frames.append(plt)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True)\n",
    "#         plt.title(f\"Distribution of {col}\")\n",
    "#         frames.append(plt)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} default frames\")\n",
    "#     return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T13:32:14.493227Z",
     "iopub.status.busy": "2025-01-03T13:32:14.492944Z",
     "iopub.status.idle": "2025-01-03T13:32:14.497203Z",
     "shell.execute_reply": "2025-01-03T13:32:14.496317Z",
     "shell.execute_reply.started": "2025-01-03T13:32:14.493207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:42:10.251413Z",
     "iopub.status.busy": "2025-01-04T07:42:10.251091Z",
     "iopub.status.idle": "2025-01-04T07:42:10.254902Z",
     "shell.execute_reply": "2025-01-04T07:42:10.253932Z",
     "shell.execute_reply.started": "2025-01-04T07:42:10.251390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = concatenate_videoclips([video, clip], method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:42:13.861209Z",
     "iopub.status.busy": "2025-01-04T07:42:13.860907Z",
     "iopub.status.idle": "2025-01-04T07:42:13.865127Z",
     "shell.execute_reply": "2025-01-04T07:42:13.864197Z",
     "shell.execute_reply.started": "2025-01-04T07:42:13.861186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_default_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:42:53.306235Z",
     "iopub.status.busy": "2025-01-03T12:42:53.306048Z",
     "iopub.status.idle": "2025-01-03T12:42:53.322383Z",
     "shell.execute_reply": "2025-01-03T12:42:53.321636Z",
     "shell.execute_reply.started": "2025-01-03T12:42:53.306219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n",
    "# # # Predefined prompts for prompt engineering\n",
    "# # predefined_prompts = [\n",
    "# #     \"Analyze the sales trends over time and regional performance.\",\n",
    "# #     \"Identify key trends, comparisons, distributions, and correlations in the data.\",\n",
    "# #     \"Generate insights on the performance and growth of different regions.\",\n",
    "# #     \"Highlight any anomalies or outliers in the sales data.\",\n",
    "# #     \"Compare the sales performance across different product categories.\",\n",
    "# #     \"Analyze the correlation between sales and marketing spend.\",\n",
    "# #     \"Identify patterns in customer purchase behavior.\",\n",
    "# #     \"Generate insights on the distribution of sales across different regions.\",\n",
    "# #     \"Analyze the relationship between sales and customer demographics.\",\n",
    "# #     \"Identify key performance indicators for the sales team.\",\n",
    "# #     # Add more prompts as needed\n",
    "# # ]\n",
    "\n",
    "# # # Test the pipeline with predefined prompts\n",
    "# # for test_prompt in predefined_prompts:\n",
    "# #     try:\n",
    "# #         logging.info(f\"Testing with prompt: {test_prompt}\")\n",
    "# #         data_storytelling_pipeline(file_path, test_prompt, audio_file=audio_file)\n",
    "# #     except Exception as e:\n",
    "# #         logging.error(f\"Error with prompt '{test_prompt}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:42:53.323406Z",
     "iopub.status.busy": "2025-01-03T12:42:53.323142Z",
     "iopub.status.idle": "2025-01-03T12:42:53.339760Z",
     "shell.execute_reply": "2025-01-03T12:42:53.338997Z",
     "shell.execute_reply.started": "2025-01-03T12:42:53.323387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "# import numpy as np\n",
    "\n",
    "# def generate_default_frames(data):\n",
    "#     logging.info(\"Generating default frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             plt.figure(figsize=(10, 6))\n",
    "#             for col in numeric_columns:\n",
    "#                 plt.plot(data[date_column], data[col], label=col)\n",
    "#             plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             plt.xlabel('Time')\n",
    "#             plt.ylabel('Values')\n",
    "#             plt.xticks(rotation=45)\n",
    "#             plt.legend()\n",
    "#             frames.append(plt)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "#         plt.title('Correlation Matrix')\n",
    "#         frames.append(plt)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True)\n",
    "#         plt.title(f\"Distribution of {col}\")\n",
    "#         frames.append(plt)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} default frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame.canvas.buffer_rgba())], fps=24) for frame in frames]\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = concatenate_videoclips([video, clip], method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_default_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD MODEL CODE IMPLEMENTATION TILL HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING CODE COMMENTED FOR REFERANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:51:53.679086Z",
     "iopub.status.busy": "2025-01-04T07:51:53.678739Z",
     "iopub.status.idle": "2025-01-04T07:51:53.684871Z",
     "shell.execute_reply": "2025-01-04T07:51:53.683933Z",
     "shell.execute_reply.started": "2025-01-04T07:51:53.679063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "# import numpy as np\n",
    "# import io\n",
    "\n",
    "# def generate_default_frames(data):\n",
    "#     logging.info(\"Generating default frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             for col in numeric_columns:\n",
    "#                 ax.plot(data[date_column], data[col], label=col)\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "#             buf = io.BytesIO()\n",
    "#             fig.savefig(buf, format='png')\n",
    "#             buf.seek(0)\n",
    "#             img = Image.open(buf)\n",
    "#             frames.append(img)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} default frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = concatenate_videoclips([video, clip], method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_default_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:51:58.449144Z",
     "iopub.status.busy": "2025-01-04T07:51:58.448794Z",
     "iopub.status.idle": "2025-01-04T07:51:58.454598Z",
     "shell.execute_reply": "2025-01-04T07:51:58.453381Z",
     "shell.execute_reply.started": "2025-01-04T07:51:58.449116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(img)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = concatenate_videoclips([video, clip], method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:52:01.358680Z",
     "iopub.status.busy": "2025-01-04T07:52:01.358384Z",
     "iopub.status.idle": "2025-01-04T07:52:01.363604Z",
     "shell.execute_reply": "2025-01-04T07:52:01.362707Z",
     "shell.execute_reply.started": "2025-01-04T07:52:01.358658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(img)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     # Add transitions between clips\n",
    "#     def add_transition(clip1, clip2, duration=1):\n",
    "#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = add_transition(video, clip)\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:43:34.627343Z",
     "iopub.status.busy": "2025-01-03T12:43:34.627049Z",
     "iopub.status.idle": "2025-01-03T12:43:34.637150Z",
     "shell.execute_reply": "2025-01-03T12:43:34.636476Z",
     "shell.execute_reply.started": "2025-01-03T12:43:34.627315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(img)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     # Add transitions between clips\n",
    "#     def add_transition(clip1, clip2, duration=1):\n",
    "#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = add_transition(video, clip)\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     # Add a title screen\n",
    "#     title = TextClip(\"Data Storytelling\", fontsize=70, color='white', bg_color='black', size=video.size)\n",
    "#     title = title.set_duration(3).fadein(1).fadeout(1)\n",
    "#     video = concatenate_videoclips([title, video])\n",
    "    \n",
    "#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:43:34.638222Z",
     "iopub.status.busy": "2025-01-03T12:43:34.637965Z",
     "iopub.status.idle": "2025-01-03T12:43:34.656841Z",
     "shell.execute_reply": "2025-01-03T12:43:34.656041Z",
     "shell.execute_reply.started": "2025-01-03T12:43:34.638196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install imagemagick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:43:34.657780Z",
     "iopub.status.busy": "2025-01-03T12:43:34.657548Z",
     "iopub.status.idle": "2025-01-03T12:43:34.672309Z",
     "shell.execute_reply": "2025-01-03T12:43:34.671394Z",
     "shell.execute_reply.started": "2025-01-03T12:43:34.657748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(img)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     # Add transitions between clips\n",
    "#     def add_transition(clip1, clip2, duration=1):\n",
    "#         return concatenate_videoclips([clip1.crossfadeout(duration), clip2.crossfadein(duration)], method=\"compose\")\n",
    "    \n",
    "#     video = video_clips[0]\n",
    "#     for clip in video_clips[1:]:\n",
    "#         video = add_transition(video, clip)\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     # Add a title screen\n",
    "#     title = TextClip(\"Data Storytelling\", fontsize=70, color='white', bg_color='black', size=video.size)\n",
    "#     title = title.set_duration(3).fadein(1).fadeout(1)\n",
    "#     video = concatenate_videoclips([title, video])\n",
    "    \n",
    "#     video = video.set_duration(max(60, video.duration))  # Ensure video is at least 60 seconds long\n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:43:34.673471Z",
     "iopub.status.busy": "2025-01-03T12:43:34.673142Z",
     "iopub.status.idle": "2025-01-03T12:43:34.692178Z",
     "shell.execute_reply": "2025-01-03T12:43:34.691140Z",
     "shell.execute_reply.started": "2025-01-03T12:43:34.673441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# import cv2\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(np.array(img))\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"new_final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     height, width, layers = frames[0].shape\n",
    "#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n",
    "    \n",
    "#     for frame in frames:\n",
    "#         video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "#     video.release()\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:43:34.693224Z",
     "iopub.status.busy": "2025-01-03T12:43:34.692941Z",
     "iopub.status.idle": "2025-01-03T12:43:34.704502Z",
     "shell.execute_reply": "2025-01-03T12:43:34.703711Z",
     "shell.execute_reply.started": "2025-01-03T12:43:34.693189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# import cv2\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(np.array(img))\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"second_final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     height, width, layers = frames[0].shape\n",
    "#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n",
    "    \n",
    "#     # Add a title screen\n",
    "#     title_screen = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "#     title_screen.fill(0)  # Black background\n",
    "#     cv2.putText(title_screen, \"Data Storytelling\", (50, height // 2), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "#     for _ in range(72):  # 3 seconds at 24 fps\n",
    "#         video.write(title_screen)\n",
    "    \n",
    "#     for frame in frames:\n",
    "#         for _ in range(3):  # Repeat each frame to slow down the video\n",
    "#             video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "#     # Ensure video is at least 60 seconds long\n",
    "#     while video.get(cv2.CAP_PROP_FRAME_COUNT) < 60 * 24:\n",
    "#         video.write(title_screen)\n",
    "    \n",
    "#     video.release()\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T12:43:34.705590Z",
     "iopub.status.busy": "2025-01-03T12:43:34.705374Z",
     "iopub.status.idle": "2025-01-03T12:43:34.720035Z",
     "shell.execute_reply": "2025-01-03T12:43:34.719342Z",
     "shell.execute_reply.started": "2025-01-03T12:43:34.705572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data)//10, blit=True)\n",
    "#             for i in range(len(data)//10):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(np.array(img))\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a moving bar chart\n",
    "#     if 'category' in data.columns and 'value' in data.columns:\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         categories = data['category'].unique()\n",
    "#         bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "#         ax.set_ylim(0, data['value'].max())\n",
    "#         ax.set_title('Moving Bar Chart')\n",
    "#         ax.set_xlabel('Category')\n",
    "#         ax.set_ylabel('Value')\n",
    "\n",
    "#         def update_bar(frame):\n",
    "#             for bar, category in zip(bars, categories):\n",
    "#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n",
    "#             return bars\n",
    "\n",
    "#         ani = FuncAnimation(fig, update_bar, frames=len(data)//10, blit=True)\n",
    "#         for i in range(len(data)//10):\n",
    "#             update_bar(i)\n",
    "#             buf = io.BytesIO()\n",
    "#             fig.savefig(buf, format='png')\n",
    "#             buf.seek(0)\n",
    "#             img = Image.open(buf)\n",
    "#             frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate a pairplot for numeric columns\n",
    "#     if len(numeric_columns) > 1:\n",
    "#         sns.pairplot(data[numeric_columns])\n",
    "#         plt.suptitle('Pairplot of Numeric Columns', y=1.02)\n",
    "#         buf = io.BytesIO()\n",
    "#         plt.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close()\n",
    "    \n",
    "#     # Generate a line plot for each numeric column\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         ax.plot(data.index, data[col])\n",
    "#         ax.set_title(f\"Line Plot of {col}\")\n",
    "#         ax.set_xlabel('Index')\n",
    "#         ax.set_ylabel(col)\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     height, width, layers = frames[0].shape\n",
    "#     video = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc(*'mp4v'), 24, (width, height))\n",
    "    \n",
    "#     for frame in frames:\n",
    "#         video.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "#     video.release()\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data_start_time = time.time()\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "#         logging.info(f\"Data loading and preprocessing took {time.time() - data_start_time:.2f} seconds\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_start_time = time.time()\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "#         logging.info(f\"EDA took {time.time() - eda_start_time:.2f} seconds\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         prompt_start_time = time.time()\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "#         logging.info(f\"Prompt analysis took {time.time() - prompt_start_time:.2f} seconds\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         video_start_time = time.time()\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "#         logging.info(f\"Video creation took {time.time() - video_start_time:.2f} seconds\")\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:52:13.335051Z",
     "iopub.status.busy": "2025-01-04T07:52:13.334745Z",
     "iopub.status.idle": "2025-01-04T07:52:13.340672Z",
     "shell.execute_reply": "2025-01-04T07:52:13.339766Z",
     "shell.execute_reply.started": "2025-01-04T07:52:13.335028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "# import io\n",
    "# from PIL import Image\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# def generate_animated_bar_chart(data):\n",
    "#     frames = []\n",
    "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#     categories = data['category'].unique()\n",
    "#     bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "#     ax.set_ylim(0, data['value'].max())\n",
    "#     ax.set_title('Moving Bar Chart')\n",
    "#     ax.set_xlabel('Category')\n",
    "#     ax.set_ylabel('Value')\n",
    "\n",
    "#     def update_bar(frame):\n",
    "#         for bar, category in zip(bars, categories):\n",
    "#             bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n",
    "#         return bars\n",
    "\n",
    "#     ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n",
    "#     for i in range(len(data)):\n",
    "#         update_bar(i)\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#     plt.close(fig)\n",
    "#     return frames\n",
    "\n",
    "# def generate_animated_correlation_matrix(data):\n",
    "#     frames = []\n",
    "#     corr_matrix = data.corr()\n",
    "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#     sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#     ax.set_title('Correlation Matrix')\n",
    "#     buf = io.BytesIO()\n",
    "#     fig.savefig(buf, format='png')\n",
    "#     buf.seek(0)\n",
    "#     img = Image.open(buf)\n",
    "#     frames.append(np.array(img))\n",
    "#     plt.close(fig)\n",
    "#     return frames\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate animated bar chart frames\n",
    "#     if 'category' in data.columns and 'value' in data.columns:\n",
    "#         frames.extend(generate_animated_bar_chart(data))\n",
    "    \n",
    "#     # Generate animated correlation matrix frames\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         frames.extend(generate_animated_correlation_matrix(data))\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"module_generation_seaborn.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = [ImageSequenceClip([np.array(frame)], fps=24) for frame in frames]\n",
    "    \n",
    "#     video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:52:16.654145Z",
     "iopub.status.busy": "2025-01-04T07:52:16.653846Z",
     "iopub.status.idle": "2025-01-04T07:52:16.659106Z",
     "shell.execute_reply": "2025-01-04T07:52:16.658264Z",
     "shell.execute_reply.started": "2025-01-04T07:52:16.654123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# def generate_default_frames(data):\n",
    "#     logging.info(\"Generating default frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             for col in numeric_columns:\n",
    "#                 ax.plot(data[date_column], data[col], label=col)\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "#             buf = io.BytesIO()\n",
    "#             fig.savefig(buf, format='png')\n",
    "#             buf.seek(0)\n",
    "#             img = Image.open(buf)\n",
    "#             frames.append(img)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(img)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} default frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"frames_animations.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = []\n",
    "#     for frame in frames:\n",
    "#         img_clip = ImageSequenceClip([np.array(frame)], fps=1)  # 1 frame per second\n",
    "#         img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n",
    "#         video_clips.append(img_clip)\n",
    "    \n",
    "#     video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_default_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:52:20.867142Z",
     "iopub.status.busy": "2025-01-04T07:52:20.866847Z",
     "iopub.status.idle": "2025-01-04T07:52:20.872759Z",
     "shell.execute_reply": "2025-01-04T07:52:20.871820Z",
     "shell.execute_reply.started": "2025-01-04T07:52:20.867120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install gtts\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from gtts import gTTS\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(np.array(img))\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a moving bar chart\n",
    "#     if 'category' in data.columns and 'value' in data.columns:\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         categories = data['category'].unique()\n",
    "#         bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "#         ax.set_ylim(0, data['value'].max())\n",
    "#         ax.set_title('Moving Bar Chart')\n",
    "#         ax.set_xlabel('Category')\n",
    "#         ax.set_ylabel('Value')\n",
    "\n",
    "#         def update_bar(frame):\n",
    "#             for bar, category in zip(bars, categories):\n",
    "#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n",
    "#             return bars\n",
    "\n",
    "#         ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n",
    "#         for i in range(len(data)):\n",
    "#             update_bar(i)\n",
    "#             buf = io.BytesIO()\n",
    "#             fig.savefig(buf, format='png')\n",
    "#             buf.seek(0)\n",
    "#             img = Image.open(buf)\n",
    "#             frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"composition_model.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = []\n",
    "#     for frame in frames:\n",
    "#         img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n",
    "#         img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n",
    "#         video_clips.append(img_clip)\n",
    "    \n",
    "#     video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "#     tts = gTTS(text=text, lang='en')\n",
    "#     tts.save(output_file)\n",
    "#     return output_file\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Generating narration...\")\n",
    "#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "#         narration_file = generate_narration(narration_text)\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:52:22.586455Z",
     "iopub.status.busy": "2025-01-04T07:52:22.586136Z",
     "iopub.status.idle": "2025-01-04T07:52:22.591732Z",
     "shell.execute_reply": "2025-01-04T07:52:22.590857Z",
     "shell.execute_reply.started": "2025-01-04T07:52:22.586431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from gtts import gTTS\n",
    "\n",
    "# def generate_animated_gifs(data):\n",
    "#     logging.info(\"Generating animated GIFs from data\")\n",
    "#     gif_files = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             gif_file = \"time_series.gif\"\n",
    "#             ani.save(gif_file, writer='imagemagick')\n",
    "#             gif_files.append(gif_file)\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate a moving bar chart\n",
    "#     if 'category' in data.columns and 'value' in data.columns:\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         categories = data['category'].unique()\n",
    "#         bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "#         ax.set_ylim(0, data['value'].max())\n",
    "#         ax.set_title('Moving Bar Chart')\n",
    "#         ax.set_xlabel('Category')\n",
    "#         ax.set_ylabel('Value')\n",
    "\n",
    "#         def update_bar(frame):\n",
    "#             for bar, category in zip(bars, categories):\n",
    "#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n",
    "#             return bars\n",
    "\n",
    "#         ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n",
    "#         gif_file = \"moving_bar_chart.gif\"\n",
    "#         ani.save(gif_file, writer='imagemagick')\n",
    "#         gif_files.append(gif_file)\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         img.save(\"correlation_matrix.png\")\n",
    "#         gif_files.append(\"correlation_matrix.png\")\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         img.save(f\"distribution_{col}.png\")\n",
    "#         gif_files.append(f\"distribution_{col}.png\")\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(gif_files)} animated GIFs and images\")\n",
    "#     return gif_files\n",
    "\n",
    "# def create_video_from_gifs(gif_files, audio_file=None, video_file=\"gif_composition_video.mp4\"):\n",
    "#     if not gif_files:\n",
    "#         raise ValueError(\"No GIF files to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from GIF files\")\n",
    "#     video_clips = []\n",
    "#     for gif_file in gif_files:\n",
    "#         if gif_file.endswith('.gif'):\n",
    "#             img_clip = ImageSequenceClip(gif_file, fps=1)  # 1 frame per second\n",
    "#         else:\n",
    "#             img_clip = ImageSequenceClip([gif_file], fps=1)  # 1 frame per second\n",
    "#         img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n",
    "#         video_clips.append(img_clip)\n",
    "    \n",
    "#     video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     gif_files = generate_animated_gifs(data)\n",
    "#     if not gif_files:\n",
    "#         raise ValueError(\"No GIF files generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         gif_files.insert(0, title_image)\n",
    "    \n",
    "#     create_video_from_gifs(gif_files, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "#     tts = gTTS(text=text, lang='en')\n",
    "#     tts.save(output_file)\n",
    "#     return output_file\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Generating narration...\")\n",
    "#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "#         narration_file = generate_narration(narration_text)\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "# prompt = \"Analyze the country and region data\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T07:52:26.326312Z",
     "iopub.status.busy": "2025-01-04T07:52:26.326017Z",
     "iopub.status.idle": "2025-01-04T07:52:26.332005Z",
     "shell.execute_reply": "2025-01-04T07:52:26.331202Z",
     "shell.execute_reply.started": "2025-01-04T07:52:26.326290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import logging\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "# import numpy as np\n",
    "# import io\n",
    "# import pandas as pd\n",
    "# import time\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from gtts import gTTS\n",
    "\n",
    "# def generate_animated_frames(data):\n",
    "#     logging.info(\"Generating animated frames from data\")\n",
    "#     frames = []\n",
    "    \n",
    "#     # Generate a basic time series plot if a date column is present\n",
    "#     date_column = None\n",
    "#     for col in data.columns:\n",
    "#         if 'date' in col.lower() or 'time' in col.lower():\n",
    "#             date_column = col\n",
    "#             break\n",
    "    \n",
    "#     if date_column:\n",
    "#         numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         if len(numeric_columns) > 0:\n",
    "#             fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#             lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "#             ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "#             ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "#             ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "#             ax.set_xlabel('Time')\n",
    "#             ax.set_ylabel('Values')\n",
    "#             ax.legend()\n",
    "\n",
    "#             def update(frame):\n",
    "#                 for line, col in zip(lines, numeric_columns):\n",
    "#                     line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "#                 return lines\n",
    "\n",
    "#             ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "#             for i in range(len(data)):\n",
    "#                 update(i)\n",
    "#                 buf = io.BytesIO()\n",
    "#                 fig.savefig(buf, format='png')\n",
    "#                 buf.seek(0)\n",
    "#                 img = Image.open(buf)\n",
    "#                 frames.append(np.array(img))\n",
    "#             plt.close(fig)\n",
    "    \n",
    "#     # Generate an animated bar chart\n",
    "#     if 'category' in data.columns and 'value' in data.columns:\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         categories = data['category'].unique()\n",
    "#         bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "#         ax.set_ylim(0, data['value'].max())\n",
    "#         ax.set_title('Animated Bar Chart')\n",
    "#         ax.set_xlabel('Category')\n",
    "#         ax.set_ylabel('Value')\n",
    "\n",
    "#         def update_bar(frame):\n",
    "#             for bar, category in zip(bars, categories):\n",
    "#                 bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n",
    "#             return bars\n",
    "\n",
    "#         ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n",
    "#         for i in range(len(data)):\n",
    "#             update_bar(i)\n",
    "#             buf = io.BytesIO()\n",
    "#             fig.savefig(buf, format='png')\n",
    "#             buf.seek(0)\n",
    "#             img = Image.open(buf)\n",
    "#             frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate an animated pie chart\n",
    "#     if 'category' in data.columns and 'value' in data.columns:\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         def update_pie(frame):\n",
    "#             ax.clear()\n",
    "#             ax.pie(data['value'][:frame], labels=data['category'][:frame], autopct='%1.1f%%')\n",
    "#             ax.set_title('Animated Pie Chart')\n",
    "\n",
    "#         ani = FuncAnimation(fig, update_pie, frames=len(data), blit=True)\n",
    "#         for i in range(len(data)):\n",
    "#             update_pie(i)\n",
    "#             buf = io.BytesIO()\n",
    "#             fig.savefig(buf, format='png')\n",
    "#             buf.seek(0)\n",
    "#             img = Image.open(buf)\n",
    "#             frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate a correlation matrix plot\n",
    "#     if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "#         corr_matrix = data.corr()\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "#         ax.set_title('Correlation Matrix')\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     # Generate distribution plots for numeric columns\n",
    "#     numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#     for col in numeric_columns:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#         sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "#         ax.set_title(f\"Distribution of {col}\")\n",
    "#         buf = io.BytesIO()\n",
    "#         fig.savefig(buf, format='png')\n",
    "#         buf.seek(0)\n",
    "#         img = Image.open(buf)\n",
    "#         frames.append(np.array(img))\n",
    "#         plt.close(fig)\n",
    "    \n",
    "#     logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "#     return frames\n",
    "\n",
    "# def create_video_from_frames(frames, audio_file=None, video_file=\"gif_new_composition.mp4\"):\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "#     logging.info(\"Creating video from frames\")\n",
    "#     video_clips = []\n",
    "#     for frame in frames:\n",
    "#         img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n",
    "#         img_clip = img_clip.set_duration(2)  # Each frame lasts 2 seconds\n",
    "#         video_clips.append(img_clip)\n",
    "    \n",
    "#     video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "#     if audio_file and os.path.isfile(audio_file):\n",
    "#         audio = AudioFileClip(audio_file)\n",
    "#         video = video.set_audio(audio)\n",
    "    \n",
    "#     video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "#     logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     frames = generate_animated_frames(data)\n",
    "#     if not frames:\n",
    "#         raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "#     if os.path.exists(title_image):\n",
    "#         title_image_clip = Image.open(title_image)\n",
    "#         title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "#         title_image_clip = np.array(title_image_clip)\n",
    "#         frames.insert(0, title_image_clip)\n",
    "    \n",
    "#     create_video_from_frames(frames, audio_file)\n",
    "#     print(\"Video successfully generated!\")\n",
    "\n",
    "# def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "#     tts = gTTS(text=text, lang='en')\n",
    "#     tts.save(output_file)\n",
    "#     return output_file\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Generating narration...\")\n",
    "#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "#         narration_file = generate_narration(narration_text)\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2017.csv'\n",
    "# prompt = \"compare the family and generaosity in an interactive video format\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-04T07:35:39.849734Z",
     "iopub.status.idle": "2025-01-04T07:35:39.850025Z",
     "shell.execute_reply": "2025-01-04T07:35:39.849916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# import os\n",
    "# import time\n",
    "# from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n",
    "# from gtts import gTTS\n",
    "# from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "# import spacy\n",
    "# import re\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setting up logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# # Load spaCy model for NER\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# import plotly.express as px\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# import os\n",
    "# import time\n",
    "# from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n",
    "# from gtts import gTTS\n",
    "# from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "# import spacy\n",
    "# import re\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setting up logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# # Load spaCy model for NER\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def load_and_preprocess_data(file_path):\n",
    "#     try:\n",
    "#         logging.info(f\"Loading data from {file_path}\")\n",
    "#         print(f\"Loading data from {file_path}\")\n",
    "#         # Load data\n",
    "#         if file_path.endswith('.csv'):\n",
    "#             data = pd.read_csv(file_path)\n",
    "#         elif file_path.endswith('.xlsx'):\n",
    "#             data = pd.read_excel(file_path)\n",
    "#         elif file_path.endswith('.txt'):\n",
    "#             data = pd.read_csv(file_path, delimiter='\\t')\n",
    "#         else:\n",
    "#             raise ValueError(\"Unsupported file format.\")\n",
    "        \n",
    "#         logging.info(\"Data loaded successfully\")\n",
    "#         print(\"Data loaded successfully\")\n",
    "        \n",
    "#         # Detect and convert data types\n",
    "#         for col in data.columns:\n",
    "#             try:\n",
    "#                 data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "#             except ValueError:\n",
    "#                 pass\n",
    "        \n",
    "#         # Handle missing values\n",
    "#         data.fillna(data.mean(), inplace=True)\n",
    "        \n",
    "#         # Handle categorical data\n",
    "#         categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "#         data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "        \n",
    "#         # Normalize numeric data\n",
    "#         numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         scaler = StandardScaler()\n",
    "#         data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "        \n",
    "#         # Add default columns if missing\n",
    "#         if 'date' not in data.columns:\n",
    "#             data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n",
    "#         if 'value' not in data.columns:\n",
    "#             data['value'] = 1  # Default value\n",
    "#         if 'category' not in data.columns:\n",
    "#             data['category'] = 'default_category'\n",
    "        \n",
    "#         logging.info(\"Data preprocessing completed\")\n",
    "#         print(\"Data preprocessing completed\")\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error loading and preprocessing data: {e}\")\n",
    "#         print(f\"Error loading and preprocessing data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # The rest of the code remains the same\n",
    "\n",
    "# def infer_columns(data):\n",
    "#     try:\n",
    "#         column_mapping = {}\n",
    "#         possible_columns = {\n",
    "#             'category': ['category', 'type', 'class', 'label', 'country', 'region'],\n",
    "#             'value': ['value', 'amount', 'score', 'total', 'family', 'generosity'],\n",
    "#             'date': ['date', 'time', 'year', 'month', 'day'],\n",
    "#             'x': ['x', 'longitude', 'lat', 'latitude'],\n",
    "#             'y': ['y', 'latitude', 'long', 'longitude']\n",
    "#         }\n",
    "        \n",
    "#         logging.info(f\"Data columns: {data.columns.tolist()}\")\n",
    "#         print(f\"Data columns: {data.columns.tolist()}\")\n",
    "#         for key, patterns in possible_columns.items():\n",
    "#             for pattern in patterns:\n",
    "#                 potential_cols = [col for col in data.columns if re.search(pattern, col, re.IGNORECASE)]\n",
    "#                 if potential_cols:\n",
    "#                     column_mapping[key] = potential_cols[0]\n",
    "#                     break\n",
    "        \n",
    "#         # If any required column is missing, attempt to infer it\n",
    "#         if 'date' not in column_mapping:\n",
    "#             data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n",
    "#             column_mapping['date'] = 'date'\n",
    "        \n",
    "#         if 'value' not in column_mapping:\n",
    "#             numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#             if len(numeric_cols) > 0:\n",
    "#                 column_mapping['value'] = numeric_cols[0]\n",
    "#             else:\n",
    "#                 raise ValueError(\"Cannot infer 'value' column.\")\n",
    "        \n",
    "#         if 'category' not in column_mapping:\n",
    "#             categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "#             if len(categorical_cols) > 0:\n",
    "#                 column_mapping['category'] = categorical_cols[0]\n",
    "#             else:\n",
    "#                 non_numeric_cols = data.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "#                 if len(non_numeric_cols) > 0:\n",
    "#                     column_mapping['category'] = non_numeric_cols[0]\n",
    "#                 else:\n",
    "#                     raise ValueError(\"Cannot infer 'category' column.\")\n",
    "        \n",
    "#         return column_mapping\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error inferring columns: {e}\")\n",
    "#         print(f\"Error inferring columns: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def generate_frames(data, chart_type, column_mapping, output_dir=\"frames\"):\n",
    "#     try:\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "        \n",
    "#         frames = []\n",
    "#         for date in data[column_mapping['date']].unique():\n",
    "#             filtered_data = data[data[column_mapping['date']] == date]\n",
    "#             if chart_type == 'bar':\n",
    "#                 fig = px.bar(filtered_data, x=column_mapping['category'], y=column_mapping['value'], title=f\"Bar Chart - {date}\")\n",
    "#             elif chart_type == 'pie':\n",
    "#                 fig = px.pie(filtered_data, values=column_mapping['value'], names=column_mapping['category'], title=f\"Pie Chart - {date}\")\n",
    "#             elif chart_type == 'scatter':\n",
    "#                 fig = px.scatter(filtered_data, x=column_mapping['x'], y=column_mapping['y'], size=column_mapping['value'], color=column_mapping['category'], title=f\"Scatter Plot - {date}\")\n",
    "#             else:\n",
    "#                 raise ValueError(\"Invalid chart type\")\n",
    "            \n",
    "#             frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n",
    "#             fig.write_image(frame_path)\n",
    "#             frames.append(frame_path)\n",
    "        \n",
    "#         return frames\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error generating frames: {e}\")\n",
    "#         print(f\"Error generating frames: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n",
    "#     try:\n",
    "#         clip = ImageSequenceClip(frames, fps=fps)\n",
    "#         clip.write_videofile(output_file, codec=\"libx264\")\n",
    "#         return output_file\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error generating video from frames: {e}\")\n",
    "#         print(f\"Error generating video from frames: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "#     try:\n",
    "#         logging.info(\"Checking data columns for required visualizations\")\n",
    "#         print(\"Checking data columns for required visualizations\")\n",
    "#         column_mapping = infer_columns(data)\n",
    "#         logging.debug(f\"Column mapping: {column_mapping}\")\n",
    "#         print(f\"Column mapping: {column_mapping}\")\n",
    "#         video_files = generate_videos_if_needed(data, column_mapping)\n",
    "        \n",
    "#         if not video_files:\n",
    "#             logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "#             print(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "#             raise ValueError(\"No video files generated from data.\")\n",
    "        \n",
    "#         logging.info(\"Combining video files into a single video\")\n",
    "#         print(\"Combining video files into a single video\")\n",
    "#         video_clips = [VideoFileClip(video_file) for video_file in video_files]\n",
    "        \n",
    "#         if os.path.exists(title_image):\n",
    "#             title_clip = VideoFileClip(title_image).set_duration(5)\n",
    "#             video_clips.insert(0, title_clip)\n",
    "        \n",
    "#         final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "        \n",
    "#         if audio_file and os.path.isfile(audio_file):\n",
    "#             audio = AudioFileClip(audio_file)\n",
    "#             final_video = final_video.set_audio(audio)\n",
    "        \n",
    "#         final_video.write_videofile(\"attemot_video.mp4\", codec=\"libx264\", fps=24)\n",
    "#         logging.info(\"Final video saved as final_video.mp4\")\n",
    "#         print(\"Final video saved as final_video.mp4\")\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error generating infographic video: {e}\")\n",
    "# def generate_videos_if_needed(data, column_mapping):\n",
    "#         raise\n",
    "\n",
    "# def generate_videos_if_needed(data):\n",
    "#     try:\n",
    "#         video_files = []\n",
    "#         column_mapping = infer_columns(data)\n",
    "#         required_columns = {'category', 'value', 'date'}\n",
    "#         if not required_columns.issubset(column_mapping.keys()):\n",
    "#             logging.error(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "#             print(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "#             raise ValueError(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "\n",
    "#         if required_columns.issubset(column_mapping.keys()):\n",
    "#             logging.info(\"Data contains required columns for bar and pie charts\")\n",
    "#             print(\"Data contains required columns for bar and pie charts\")\n",
    "#             try:\n",
    "#                 bar_frames = generate_frames(data, 'bar', column_mapping)\n",
    "#                 video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Failed to generate animated bar chart: {e}\")\n",
    "#                 print(f\"Failed to generate animated bar chart: {e}\")\n",
    "#             try:\n",
    "#                 pie_frames = generate_frames(data, 'pie', column_mapping)\n",
    "#                 video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Failed to generate animated pie chart: {e}\")\n",
    "#                 print(f\"Failed to generate animated pie chart: {e}\")\n",
    "#         if {'x', 'y', 'value', 'date'}.issubset(column_mapping.keys()):\n",
    "#             logging.info(\"Data contains required columns for scatter plot\")\n",
    "#             print(\"Data contains required columns for scatter plot\")\n",
    "#             try:\n",
    "#                 scatter_frames = generate_frames(data, 'scatter', column_mapping)\n",
    "#                 video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n",
    "#             except Exception as e:\n",
    "#                 logging.error(f\"Failed to generate animated scatter plot: {e}\")\n",
    "#                 print(f\"Failed to generate animated scatter plot: {e}\")\n",
    "#         return video_files\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error generating videos if needed: {e}\")\n",
    "#         print(f\"Error generating videos if needed: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "#     try:\n",
    "#         tts = gTTS(text=text, lang='en')\n",
    "#         tts.save(output_file)\n",
    "#         return output_file\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error generating narration: {e}\")\n",
    "#         print(f\"Error generating narration: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def perform_eda(data):\n",
    "#     try:\n",
    "#         eda_summary = {\n",
    "#             \"shape\": data.shape,\n",
    "#             \"columns\": data.columns.tolist(),\n",
    "#             \"dtypes\": data.dtypes.tolist(),\n",
    "#             \"null_counts\": data.isnull().sum().tolist(),\n",
    "#             \"describe\": data.describe().to_dict()\n",
    "#         }\n",
    "#         return eda_summary\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error performing EDA: {e}\")\n",
    "#         print(f\"Error performing EDA: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n",
    "#     try:\n",
    "#         logging.info(\"Analyzing prompt for insights\")\n",
    "#         print(\"Analyzing prompt for insights\")\n",
    "#         tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "#         model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "        \n",
    "#         inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "#         input_ids = inputs.input_ids\n",
    "#         attention_mask = inputs.attention_mask\n",
    "        \n",
    "#         outputs = model.generate(\n",
    "#             input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             max_length=200,\n",
    "#             num_return_sequences=1,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.9,\n",
    "#             top_k=50,\n",
    "#             no_repeat_ngram_size=2,\n",
    "#             pad_token_id=tokenizer.eos_token_id\n",
    "#         )\n",
    "        \n",
    "#         generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "#         insights = extract_insights_from_text(generated_text)\n",
    "        \n",
    "#         insights_list = [key for key, value in insights.items() if value]\n",
    "#         if not insights_list:\n",
    "#             logging.warning(\"No insights could be extracted from the provided prompt. Using default insights.\")\n",
    "#             print(\"No insights could be extracted from the provided prompt. Using default insights.\")\n",
    "#             insights_list = [\"trend\", \"comparison\"]\n",
    "        \n",
    "#         logging.info(f\"Insights extracted: {insights_list}\")\n",
    "#         print(f\"Insights extracted: {insights_list}\")\n",
    "#         return insights_list\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error in analyzing prompt for insights: {e}\")\n",
    "#         print(f\"Error in analyzing prompt for insights: {e}\")\n",
    "#         return [\"trend\", \"comparison\"]\n",
    "\n",
    "# def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         logging.info(\"Loading and preprocessing data...\")\n",
    "#         print(\"Loading and preprocessing data...\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "#         print(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "#         logging.info(\"Performing EDA...\")\n",
    "#         print(\"Performing EDA...\")\n",
    "#         eda_summary = perform_eda(data)\n",
    "#         logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "#         print(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "#         logging.info(\"Analyzing the user's prompt...\")\n",
    "#         print(\"Analyzing the user's prompt...\")\n",
    "#         insights = analyze_prompt_for_insights(prompt)\n",
    "#         logging.debug(f\"Extracted insights: {insights}\")\n",
    "#         print(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "#         logging.info(\"Generating narration...\")\n",
    "#         print(\"Generating narration...\")\n",
    "#         narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "#         narration_file = generate_narration(narration_text)\n",
    "        \n",
    "#         logging.info(\"Creating the infographic video...\")\n",
    "#         print(\"Creating the infographic video...\")\n",
    "#         generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "#         print(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "#     except FileNotFoundError as fnf_error:\n",
    "#         logging.error(f\"File not found: {fnf_error}\")\n",
    "#         print(f\"File not found: {fnf_error}\")\n",
    "#         raise\n",
    "#     except pd.errors.ParserError as parser_error:\n",
    "#         logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "#         print(f\"Error parsing the file: {parser_error}\")\n",
    "#         raise\n",
    "#     except TypeError as type_error:\n",
    "#         logging.error(f\"Type error: {type_error}\")\n",
    "#         print(f\"Type error: {type_error}\")\n",
    "#         raise\n",
    "#     except ValueError as value_error:\n",
    "#         logging.error(f\"Value error: {value_error}\")\n",
    "#         print(f\"Value error: {value_error}\")\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"An unexpected error occurred: {e}\")\n",
    "#         print(f\"An unexpected error occurred: {e}\")\n",
    "#         raise\n",
    "\n",
    "# # Example usage:\n",
    "# file_path = '/kaggle/input/model-dataset-new-1/2017.csv'\n",
    "# prompt = \"analyse the family and generaosity columns data in the video format\"\n",
    "# audio_file = \"/kaggle/working/\"\n",
    "# title_image = \"/kaggle/working/\"\n",
    "\n",
    "# if not os.path.exists(file_path):\n",
    "#     raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "# if not os.path.exists(audio_file):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "# if not os.path.exists(title_image):\n",
    "#     raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "# try:\n",
    "#     data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n",
    "# except ValueError as e:\n",
    "#     if \"Missing required columns\" in str(e):\n",
    "#         logging.info(\"Adding missing columns to the data\")\n",
    "#         print(\"Adding missing columns to the data\")\n",
    "#         data = load_and_preprocess_data(file_path)\n",
    "#         column_mapping = infer_columns(data)\n",
    "        \n",
    "#         if 'date' not in column_mapping:\n",
    "#             data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n",
    "        \n",
    "#         if 'value' not in column_mapping:\n",
    "#             data['value'] = data.select_dtypes(include=['float64', 'int64']).iloc[:, 0]\n",
    "        \n",
    "#         if 'category' not in column_mapping:\n",
    "#             data['category'] = 'default_category'\n",
    "        \n",
    "#         data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n",
    "#     else:\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# will work tommorow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6413607,
     "sourceId": 10356362,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
